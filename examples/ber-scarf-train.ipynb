{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#change path, the directory where the source files are located\n","import os\n","os.chdir(\"..\")\n","import sys\n","sys.path.append(\"clear/pytorch\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:19.264639Z","iopub.status.busy":"2024-11-02T16:46:19.263869Z","iopub.status.idle":"2024-11-02T16:46:19.523393Z","shell.execute_reply":"2024-11-02T16:46:19.521872Z","shell.execute_reply.started":"2024-11-02T16:46:19.264552Z"},"trusted":true},"outputs":[],"source":["wandb_key = \"YOUR_WANDB_KEY\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:19.526908Z","iopub.status.busy":"2024-11-02T16:46:19.526348Z","iopub.status.idle":"2024-11-02T16:46:23.120766Z","shell.execute_reply":"2024-11-02T16:46:23.119485Z","shell.execute_reply.started":"2024-11-02T16:46:19.526833Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/xiaoqian/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login(key=wandb_key)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:23.122988Z","iopub.status.busy":"2024-11-02T16:46:23.122299Z","iopub.status.idle":"2024-11-02T16:46:23.518178Z","shell.execute_reply":"2024-11-02T16:46:23.517110Z","shell.execute_reply.started":"2024-11-02T16:46:23.122930Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","data_folder = 'ber-processed-parquet'\n","input_dir = f\"input/{data_folder}\"\n","output_dir = \"output\"\n","config_dir=f\"clear/pytorch/configs\"\n","scarf_model_name = \"scarf\"\n","mlp_model_name = \"mlp\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:23.520605Z","iopub.status.busy":"2024-11-02T16:46:23.519839Z","iopub.status.idle":"2024-11-02T16:46:23.557921Z","shell.execute_reply":"2024-11-02T16:46:23.556623Z","shell.execute_reply.started":"2024-11-02T16:46:23.520547Z"},"trusted":true},"outputs":[{"data":{"text/plain":["5"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","n_splits = len(list(os.walk(input_dir))[0][1])\n","n_splits"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-02T16:46:23.562095Z","iopub.status.busy":"2024-11-02T16:46:23.561576Z","iopub.status.idle":"2024-11-02T16:46:23.568224Z","shell.execute_reply":"2024-11-02T16:46:23.567050Z","shell.execute_reply.started":"2024-11-02T16:46:23.562040Z"},"trusted":true},"outputs":[],"source":["scarf_batch_size = 32\n","scarf_epochs = 10\n","scarf_lr = 0.001\n","scarf_emb_dim = 32\n","scarf_encoder_depth = 3\n","scarf_corruption_rate=0.3"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:23.570017Z","iopub.status.busy":"2024-11-02T16:46:23.569648Z","iopub.status.idle":"2024-11-02T16:46:23.579456Z","shell.execute_reply":"2024-11-02T16:46:23.578230Z","shell.execute_reply.started":"2024-11-02T16:46:23.569976Z"},"trusted":true},"outputs":[],"source":["splits = range(n_splits)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:23.594923Z","iopub.status.busy":"2024-11-02T16:46:23.594465Z","iopub.status.idle":"2024-11-02T16:46:27.795579Z","shell.execute_reply":"2024-11-02T16:46:27.794390Z","shell.execute_reply.started":"2024-11-02T16:46:23.594871Z"},"trusted":true},"outputs":[],"source":["import clear.pytorch.src as src\n","from src.utils import set_seed, load_from_yaml, get_features_from_yaml\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.797989Z","iopub.status.busy":"2024-11-02T16:46:27.797258Z","iopub.status.idle":"2024-11-02T16:46:27.803916Z","shell.execute_reply":"2024-11-02T16:46:27.802874Z","shell.execute_reply.started":"2024-11-02T16:46:27.797931Z"},"trusted":true},"outputs":[],"source":["flag_train = False\n","\n","flag_embedding = True\n","\n","mode = 'full'\n","# mode = 'batch'\n","\n","model_dir = 'output'\n","output_dir = 'output'"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.805715Z","iopub.status.busy":"2024-11-02T16:46:27.805300Z","iopub.status.idle":"2024-11-02T16:46:27.892412Z","shell.execute_reply":"2024-11-02T16:46:27.891172Z","shell.execute_reply.started":"2024-11-02T16:46:27.805667Z"},"trusted":true},"outputs":[{"data":{"text/plain":["False"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import argparse\n","import os\n","import pandas as pd\n","import wandb\n","from src.utils import set_seed, load_from_yaml, get_features_from_yaml\n","from src.data_processor import DataProcessor\n","from src.scarf import SCARF\n","from src.dataloader import ScarfToDataLoader\n","from train import train_encoder\n","from dotenv import load_dotenv\n","# Suppress Dtype and Future warnings from pandas\n","import warnings\n","warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","import torch\n","# Set a consistent seed for reproducibility\n","set_seed(42)\n","load_dotenv()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.894570Z","iopub.status.busy":"2024-11-02T16:46:27.894146Z","iopub.status.idle":"2024-11-02T16:46:27.918240Z","shell.execute_reply":"2024-11-02T16:46:27.916819Z","shell.execute_reply.started":"2024-11-02T16:46:27.894527Z"},"trusted":true},"outputs":[],"source":["\n","def run_scarf(arguments):\n","    # Argument parsing\n","    parser = argparse.ArgumentParser(description='Train SCARF model')\n","    parser.add_argument('--config_dir', default='configs', help='Directory for configuration files')\n","    parser.add_argument('--output_dir', default='exp', help='Output directory for models and stats')\n","    parser.add_argument('--train_data_path', default='data/small_train.csv', help='Data directory')\n","    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training')\n","    parser.add_argument('--epochs', type=int, default=1, help='Number of training epochs')\n","    parser.add_argument('--lr', type=float, default=3e-5, help='Learning rate')\n","    parser.add_argument('--emb_dim', type=int, default=32, help='Dimensionality of the embedding space')\n","    parser.add_argument('--encoder_depth', type=int, default=3, help='Depth of the encoder model')\n","    parser.add_argument('--model_name', type=str, default=\"scarf\", help='Name of saved model')\n","    parser.add_argument('--corruption_rate', type=float, default=0.3, help='Rate of corruption applied during training')\n","    # parser.add_argument('--device', type=str, default=\"cpu\")\n","    parser.add_argument('--wandb_project_name', type=str, required=True, help='Name of wandb project')\n","    parser.add_argument('--wandb_entity', type=str, default=\"urbancomp\", help='Name of wandb entity')\n","    parser.add_argument('--wandb_key', type=str)\n","    args = parser.parse_args(arguments)\n","\n","    # Ensure output directory exists\n","    if not os.path.exists(args.output_dir):\n","        os.makedirs(args.output_dir)\n","\n","    # Load configurations from YAML files\n","    preprocessing_config = load_from_yaml(f\"{args.config_dir}/preprocess_config.yaml\")\n","    energy_config = load_from_yaml(f\"{args.config_dir}/energy_config.yaml\")\n","    column_type_path = f\"{args.output_dir}/column_type_classification.yaml\"\n","    train_stats_path = f\"{args.output_dir}/train_stats.json\"\n","    scaler_path = f\"{args.output_dir}/scaler.joblib\"\n","    encoder_path = f\"{args.output_dir}/encoder.joblib\"\n","    small_area_path = f\"{args.config_dir}/small_area.yaml\"\n","    target = \"EnergyRating\"\n","    feature_config = load_from_yaml(f\"{args.config_dir}/column_type_classification.yaml\")\n","    features = get_features_from_yaml(feature_config, target)\n","    energyRatingEncoding = energy_config[\"original_rating_encoding\"]\n","\n","\n","    wandb_key = os.getenv('WANDB_KEY')\n","    if not wandb_key:\n","        wandb_key = args.wandb_key\n","\n","    # Initialize Weights & Biases\n","    wandb.login(key=wandb_key)\n","    wandb.init(\n","        project=\"Scarf\",\n","        name=args.wandb_project_name,\n","        entity=args.wandb_entity,\n","        config={\n","            \"epochs\": args.epochs,\n","            \"batch_size\": args.batch_size,\n","            \"lr\": args.lr,\n","            \"feature_num\": len(features),\n","            \"class_num\": len(energyRatingEncoding),\n","            \"features\": features,\n","            \"model_save_dir\": args.output_dir,\n","            \"model_name\": args.model_name,\n","            \"emb_dim\": args.emb_dim,\n","            \"encoder_depth\": args.encoder_depth,\n","            \"corruption_rate\": args.corruption_rate,\n","        }\n","    )\n","\n","    # Load datasets\n","    data_format = args.train_data_path.split('.')[-1]\n","    if data_format == 'csv':\n","        df_train = pd.read_csv(f\"{args.train_data_path}\")\n","    elif data_format == 'parquet':\n","        df_train = pd.read_parquet(f\"{args.train_data_path}\")\n","    else:\n","        print(\"wrong data format\")\n","        return\n","\n","\n","    # # if not processed, Process datasets\n","    # processor = DataProcessor(preprocessing_config, train_stats_path, column_type_path, scaler_path, encoder_path, small_area_path, target, features)\n","    # train_df = processor.process(df_train, is_train=True)\n","\n","\n","    device = \"cuda\" if  torch.cuda.is_available() else \"cpu\"\n","    # Initialize and train the model\n","    model = SCARF(input_dim=df_train.shape[1]-1, emb_dim=args.emb_dim, encoder_depth=args.encoder_depth, corruption_rate=args.corruption_rate)\n","    model.to(device)\n","    train_encoder(df_train, \n","                  ScarfToDataLoader, \n","                  model, \n","                  device=device, \n","                  target_col=target, \n","                  batch_size=args.batch_size, \n","                  lr=args.lr, \n","                  epochs=args.epochs, \n","                  model_save_dir=args.output_dir, \n","                  model_name=args.model_name)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.938884Z","iopub.status.busy":"2024-11-02T16:46:27.938500Z","iopub.status.idle":"2024-11-02T16:46:27.950758Z","shell.execute_reply":"2024-11-02T16:46:27.949481Z","shell.execute_reply.started":"2024-11-02T16:46:27.938830Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiao-qian\u001b[0m (\u001b[33murbancomp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.18.7 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/Users/xiaoqian/coding/projects/luminlab/BerClear/wandb/run-20241114_143828-4vq77a8j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/urbancomp/Scarf/runs/4vq77a8j' target=\"_blank\">SCARF_Project</a></strong> to <a href='https://wandb.ai/urbancomp/Scarf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/urbancomp/Scarf' target=\"_blank\">https://wandb.ai/urbancomp/Scarf</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/urbancomp/Scarf/runs/4vq77a8j' target=\"_blank\">https://wandb.ai/urbancomp/Scarf/runs/4vq77a8j</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch [1/10] - Train Loss: 1.680\n","Model saved at output//scarf.pt\n","Epoch [2/10] - Train Loss: 1.709\n","Epoch [3/10] - Train Loss: 1.780\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m     train_scarf(batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mtrain_scarf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[23], line 31\u001b[0m, in \u001b[0;36mtrain_scarf\u001b[0;34m(splits, batch, tag)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     args \u001b[38;5;241m=\u001b[39m arguments \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--output_dir=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--train_data_path=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/processed.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m     ]\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mrun_scarf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[13], line 83\u001b[0m, in \u001b[0;36mrun_scarf\u001b[0;34m(arguments)\u001b[0m\n\u001b[1;32m     81\u001b[0m model \u001b[38;5;241m=\u001b[39m SCARF(input_dim\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, emb_dim\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39memb_dim, encoder_depth\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mencoder_depth, corruption_rate\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mcorruption_rate)\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 83\u001b[0m \u001b[43mtrain_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m              \u001b[49m\u001b[43mScarfToDataLoader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/coding/projects/luminlab/BerClear/clear/pytorch/train.py:100\u001b[0m, in \u001b[0;36mtrain_encoder\u001b[0;34m(train_df, DataFrameToDataLoader, model, device, target_col, batch_size, lr, epochs, model_save_dir, model_name)\u001b[0m\n\u001b[1;32m     98\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     99\u001b[0m emb_anchor, emb_positive \u001b[38;5;241m=\u001b[39m model(anchor, positive)\n\u001b[0;32m--> 100\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_anchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_positive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    102\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniforge3/envs/ber_clean/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/ber_clean/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/coding/projects/luminlab/BerClear/clear/pytorch/src/scarf.py:66\u001b[0m, in \u001b[0;36mNTXent.forward\u001b[0;34m(self, z_i, z_j)\u001b[0m\n\u001b[1;32m     63\u001b[0m sim_ji \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(similarity, \u001b[38;5;241m-\u001b[39mbatch_size)\n\u001b[1;32m     64\u001b[0m positives \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([sim_ij, sim_ji], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m numerator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(positives \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature)\n\u001b[1;32m     68\u001b[0m denominator \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(similarity \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","\"\"\"The trained scarf model is saved in \n","{root_path}/output/split_{split}/scarf.pt if you run the following command:\n","\"\"\"\n","def train_scarf(splits=5, batch=True, \n","                tag='train'):\n","    arguments = [\n","          f'--config_dir={config_dir}',\n","          f\"--batch_size={scarf_batch_size}\",\n","          f\"--epochs={scarf_epochs}\",\n","          f\"--lr={scarf_lr}\",\n","          f\"--emb_dim={scarf_emb_dim}\",\n","          f\"--encoder_depth={scarf_encoder_depth}\",\n","          f\"--model_name={scarf_model_name}\",\n","          f\"--corruption_rate={scarf_corruption_rate}\",\n","          f\"--wandb_project_name=SCARF_Project\",\n","          f\"--wandb_entity=urbancomp\",\n","        ]\n","    if batch == True:\n","        for i in splits:\n","            args = arguments + [\n","              f'--output_dir={output_dir}/split_{i+1}',\n","              f'--train_data_path={input_dir}/split_{i+1}/processed_{tag}.parquet',\n","            ]\n","            run_scarf(args)\n","    else:\n","        args = arguments + [\n","            f'--output_dir={output_dir}/',\n","            f'--train_data_path={input_dir}/processed.parquet',\n","        ]\n","        run_scarf(args)\n","\n","flag_train = True\n","if flag_train:\n","    if mode == 'batch':\n","        train_scarf(batch=True)\n","    if mode == 'full':\n","        train_scarf(batch=False)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.955895Z","iopub.status.busy":"2024-11-02T16:46:27.955404Z","iopub.status.idle":"2024-11-02T16:46:27.983248Z","shell.execute_reply":"2024-11-02T16:46:27.981959Z","shell.execute_reply.started":"2024-11-02T16:46:27.955830Z"},"trusted":true},"outputs":[],"source":["import argparse\n","import os\n","import pandas as pd\n","import torch\n","from src.utils import set_seed, load_from_yaml, get_features_from_yaml, load_model\n","from src.data_processor import DataProcessor\n","from src.scarf import SCARF\n","from src.dataloader import ScarfToDataLoader\n","# Suppress Dtype and Future warnings from pandas\n","import warnings\n","import numpy as np\n","\n","\n","\n","warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","# Set a consistent seed for reproducibility\n","set_seed(42)\n","\n","def get_scarf_embedding(arguments):\n","    # Argument parsing\n","    parser = argparse.ArgumentParser(description='Generate Embeddings')\n","    parser.add_argument('--config_dir', default='configs', help='Directory for configuration files')\n","    parser.add_argument('--model_dir', default='exp', help='Input Model directory for models')\n","    parser.add_argument('--output_dir', default='exp', help='Output directory for models and stats')\n","    parser.add_argument('--data_path', type=str, help='Specify the data path for the file you want to convert into SCARF embeddings.')\n","    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training')\n","    parser.add_argument('--epochs', type=int, default=1, help='Number of training epochs')\n","    parser.add_argument('--lr', type=float, default=3e-5, help='Learning rate')\n","    parser.add_argument('--emb_dim', type=int, default=32, help='Dimensionality of the embedding space')\n","    parser.add_argument('--encoder_depth', type=int, default=3, help='Depth of the encoder model')\n","    parser.add_argument('--model_name', type=str, default=\"scarf\", help='Name of saved model')\n","    parser.add_argument('--corruption_rate', type=float, default=0.3, help='Rate of corruption applied during training')\n","    # parser.add_argument('--device', type=str, default=\"cpu\")\n","    parser.add_argument('--embedding_save_name', type=str, required=True)\n","    args = parser.parse_args(arguments)\n","\n","    # Ensure output directory exists\n","    if not os.path.exists(args.output_dir):\n","        os.makedirs(args.output_dir)\n","\n","    device = \"cuda\" if  torch.cuda.is_available() else \"cpu\"\n","\n","    # Load configurations from YAML files\n","    preprocessing_config = load_from_yaml(f\"{args.config_dir}/preprocess_config.yaml\")\n","    energy_config = load_from_yaml(f\"{args.config_dir}/energy_config.yaml\")\n","    column_type_path = f\"{args.output_dir}/column_type_classification.yaml\"\n","    train_stats_path = f\"{args.output_dir}/train_stats.json\"\n","    scaler_path = f\"{args.output_dir}/scaler.joblib\"\n","    encoder_path = f\"{args.output_dir}/encoder.joblib\"\n","    small_area_path = f\"{args.config_dir}/small_area.yaml\"\n","    target = \"EnergyRating\"\n","    feature_config = load_from_yaml(f\"{args.config_dir}/column_type_classification.yaml\")\n","    features = get_features_from_yaml(feature_config, target)\n","    energyRatingEncoding = energy_config[\"original_rating_encoding\"]\n","\n","\n","    # Load datasets\n","    data_format = args.data_path.split('.')[-1]\n","    if data_format == 'csv':\n","        df = pd.read_csv(f\"{args.data_path}\")\n","    elif data_format == 'parquet':\n","        df = pd.read_parquet(f\"{args.data_path}\")\n","    else:\n","        print(\"wrong data format\")\n","        return\n","\n","    # Process datasets\n","    # processor = DataProcessor(preprocessing_config, train_stats_path, column_type_path, scaler_path, encoder_path, small_area_path, target, features)\n","    # data_df = processor.process(df, is_train=True)\n","\n","    # Initialize and train the model\n","    model = SCARF(input_dim=df.shape[1]-1, emb_dim=args.emb_dim, encoder_depth=args.encoder_depth, corruption_rate=args.corruption_rate)\n","    model = load_model(model_dir = args.model_dir, \n","               model_name= args.model_name,\n","               model = model,\n","               device = device)\n","\n","    model.eval()\n","    embeddings = []\n","    dataloader = ScarfToDataLoader(df, \n","                                    target_col=target, \n","                                    batch_size=args.batch_size, \n","                                    shuffle=False).dataloader\n","\n","    with torch.no_grad():\n","        for f, _ in dataloader:\n","            embeddings.append(model.get_embeddings(f.to(device)))\n","\n","    embeddings = torch.cat(embeddings, dim=0)\n","    embeddings = embeddings.cpu()\n","    embeddings_numpy= embeddings.numpy()\n","    np.save(f\"{args.output_dir}/{args.embedding_save_name}.npy\", embeddings_numpy)\n","\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:46:27.984820Z","iopub.status.busy":"2024-11-02T16:46:27.984445Z","iopub.status.idle":"2024-11-02T16:47:09.867312Z","shell.execute_reply":"2024-11-02T16:47:09.866126Z","shell.execute_reply.started":"2024-11-02T16:46:27.984779Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model loaded from output//scarf.pt\n"]}],"source":["\"\"\"The generated embeddings are saved as a NumPy array in \n","output/split_{split}/train.npy for batch mode, \n","or\n","output/processed.npy for full mode:\n","\"\"\"\n","def get_embeddings(output_dir, model_dir, splits=5, batch=True, tag='train'):\n","    arguments = [\n","          f\"--config_dir={config_dir}\",\n","\n","          f\"--batch_size={scarf_batch_size}\",\n","          f\"--epochs={scarf_epochs}\",\n","          f\"--lr={scarf_lr}\",\n","          f\"--emb_dim={scarf_emb_dim}\",\n","          f\"--encoder_depth={scarf_encoder_depth}\",\n","          f\"--model_name={scarf_model_name}\",\n","          f\"--corruption_rate={scarf_corruption_rate}\",\n","          f\"--embedding_save_name={tag}\",\n","        ]\n","    if batch == True:\n","        for i in splits:\n","            args = arguments + [\n","          f\"--output_dir={output_dir}/split_{i+1}\",\n","          f\"--model_dir={model_dir}/split_{i+1}\",\n","          f\"--data_path={input_dir}/split_{i+1}/processed_{tag}.parquet\",\n","            ]\n","            get_scarf_embedding(args)\n","    else:\n","        args = arguments + [\n","          f\"--output_dir={output_dir}/\",\n","          f\"--model_dir={model_dir}/\",\n","          f\"--data_path={input_dir}/processed.parquet\",\n","        ]\n","        get_scarf_embedding(args)\n","\n","\n","if flag_embedding:\n","    if mode == 'batch':\n","        get_embeddings(output_dir, \n","                       model_dir, splits=5)\n","    if mode == 'full':\n","        get_embeddings(output_dir, \n","                       model_dir, batch=False, tag='processed')\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T16:47:11.113196Z","iopub.status.busy":"2024-11-02T16:47:11.112761Z","iopub.status.idle":"2024-11-02T16:47:12.289006Z","shell.execute_reply":"2024-11-02T16:47:12.287590Z","shell.execute_reply.started":"2024-11-02T16:47:11.113137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["avg_scores.csv             scores_processed_2.csv\n","merged.csv                 scores_processed_3.csv\n","randomforest_processed.pkl scores_processed_4.csv\n","scores_processed_1.csv     scores_processed_5.csv\n"]}],"source":["!ls output"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5621819,"sourceId":9286959,"sourceType":"datasetVersion"},{"datasetId":5625724,"sourceId":9293454,"sourceType":"datasetVersion"},{"datasetId":5630752,"sourceId":9299748,"sourceType":"datasetVersion"},{"datasetId":5963657,"sourceId":9788133,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
